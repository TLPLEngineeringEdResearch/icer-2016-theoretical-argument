\section{Introduction}\label{Introduction}

\subsection{Misconceptions research in computing education tends to
ignore students' productive
knowledge}\label{misconceptions-research-in-computing-education-tends-to-ignore-students-productive-knowledge}

I argue research
approaches that inflexibly privilege canonical knowledge do so at the
expense of other productive knowledge and ways of knowing that students
have.

In the past three decades, educational research has had a marked focus
on students' misconceptions in programming. It's a focus with a sensible
origin. Students get things wrong in programming --- often
systematically so --- and in ways that seem resistant to instruction.
The cause of those errors is theorized to be something cognitive,
whether it's a ``bug'' \cite{pea_buggy_1987,pea_languageindependent_1986,vanlehn_mind_1990}, a
``misconception'' \cite{bayman_diagnosis_1983,bonar_preprogramming_1985,clancy_misconceptions_2004,gal-ezer_efficiency_2004,herman_proof_2008,kaczmarczyk_identifying_2010}, a ``belief'' \cite{fleury_student_1993}, or a ``student-constructed
rule'' \cite{fleury_parameter_1991,fleury_programming_2000} in programming. Instruction, Clancy argues, should try to identify,
address, and correct these misconceptions because they
can represent barriers to learning \cite{clancy_misconceptions_2004}.

How that line of thinking and research becomes problematic is two-fold.
First, when taken in total the alleged brokenness of student knowledge
begins eclipsing all else in studying the cognition of learning to
program. In other words, most cognitively-focused educational research
in computer science treats students as having varied degrees of
deficiency with respect to canonical knowledge. Below is an unordered,
partial sampling of topics about which researchers have documented
students' misconceptions. Note across the list the variation in both the
grain sizes of students' misconceptions and the programming languages in
which they manifest:

\begin{itemize}
\tightlist
\item
  Objects in object-oriented programming \cite{holland_avoiding_1997}
\item
  Algorithms and data structures \cite{danielsiek_detecting_2012,paul_hunting_2013}
\item
  Programming statements in BASIC \cite{bayman_diagnosis_1983}
\item
  Programming in Java \cite{fleury_programming_2000}
\item
  Programming in Pascal \cite{fleury_student_1993}
\item
  Parameter-passing \cite{fleury_parameter_1991}
\item
  Arrays in Java \cite{kaczmarczyk_identifying_2010}
\item
  Objects in Java \cite{kaczmarczyk_identifying_2010}
\item
  Algorithms and computational complexity \cite{trakhtenbrot_students_2013}
\item
  Boolean logic \cite{herman_proof_2008}
\item
  The efficiency of algorithms \cite{gal-ezer_efficiency_2004}
\item
  The Build-Heap algorithm \cite{seppala_observations_2006}
\item
  Hashtables \cite{patitsas_countably_2013}
\item
  The correctness of programs \cite{kolikant_my_2008}
\item
  Polynomial and mapping reduction in the Theory and Computation of Complexity \cite{gal-ezer_identification_2016}
\end{itemize}

Clancy \cite{clancy_misconceptions_2004} provides a comprehensive overview of this line of
research, though in the past decade it has only grown. Indeed, roughly
half the articles above were published in the ten years since Clancy's
overview.

Identifying and removing barriers to student learning seems like a good
thing. So, it should follow that cataloging student misconceptions and
developing remedies for them should also be a good thing. But, the
logical implication isn't that clean. In some cases students display
productive, useful knowledge that's either ignored or outright
criticized by researchers. Aligning students toward canonical knowledge
makes sense, but doing so at the expense of---or in direct contradiction
to---useful ways of knowing seems undesirable at best. Next, I expand on
two examples from misconceptions research in programming. Specifically,
I show how and why I think a misconceptions focus in programming casts
aside students' useful intuitions and understandings.

The first example comes from \cite{kaczmarczyk_identifying_2010}. Part of that
study involved giving students snippets of Java code and asking students
to diagram (or pseudo-code) how the information would be stored in
memory. Below I have reproduced the code for Problem 2:

\hypertarget{sandiwches-code}{\label{sandwiches-code}}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{Cheese[] cheeses = }\KeywordTok{new} \NormalTok{Cheese[}\DecValTok{4}\NormalTok{];}
\NormalTok{Meat[] meats = }\KeywordTok{new} \NormalTok{Meat[}\DecValTok{2}\NormalTok{];}
\NormalTok{Turkey turkey;}
\NormalTok{Ham ham;}
\NormalTok{RoastBeef roastBeef;}
\DataTypeTok{boolean} \NormalTok{lettuce = }\KeywordTok{true}\NormalTok{;}
\DataTypeTok{boolean} \NormalTok{tomato = }\KeywordTok{true}\NormalTok{;}
\NormalTok{SauceType sauceType = }\KeywordTok{new} \FunctionTok{SauceType}\NormalTok{();}
\DataTypeTok{int} \NormalTok{numMeat;}
\DataTypeTok{int} \NormalTok{numCheese;}
\end{Highlighting}
\end{Shaded}

In diagramming this information, a student in the study makes a mistake:

\begin{quote}
  Student3 makes incorrect assumptions about connections between variables
  to the extent that the student makes a mistake concerning the types of
  the variables. As a result, the student places Objects of different
  types in an array whose type matches none of them: ``And so because
  there's two arrays, cheese and meats, uh, all those turkey and ham and
  roast beef are gonna be sorted into the meats array.'' \cite{kaczmarczyk_identifying_2010}
\end{quote}

The researchers are correct in the sense that \texttt{turkey} and
\texttt{ham} and \texttt{roastBeef} will \emph{not} be sorted into the
\texttt{meats} array. First, there is no code here that places
\texttt{turkey} and \texttt{ham} in the array; there is only code that
declares them as variables. Moreover, as written, an attempt to place
\texttt{turkey} and \texttt{ham} and \texttt{roastBeef} into the array
would fail. Because of type restrictions in Java, only objects of class
Meat (or objects that inherit from class Meat) can go in the array.
\texttt{turkey} and \texttt{ham} and \texttt{roastBeef} are, perhaps
confusingly, references to object instances of classes \texttt{Turkey}
and \texttt{Ham} and \texttt{RoastBeef}, so in the current snippet they
cannot enter an array of type \texttt{Meat} because (1) they don't yet
exist as objects and (2) even if they did exist, their types don't match
the array's type. The authors call this misconception \emph{semantics to
semantics}, which occurs ``when the student inappropriately
assume{[}s{]} details about the relationship and operation of code
samples, although such information was neither given nor implied''
\cite{kaczmarczyk_identifying_2010}.

Again, the researchers are right that the student is failing to describe
the code in a way consistent with canon. But, in their non-canonical thinking Student3 evidences
potentially ``\emph{productive}'' \cite{hammer_form_2002,hammer_tapping_2003} insights about design. Precisely \emph{because}
there is no code stating that \textbf{turkey} and \textbf{roastBeef} and
ham are sorted into the array, the student is \emph{inferring} that to
be true. And, while that behavior is not what's happening, it
\emph{would} be sensible to design a program where specific instances of
classes \textbf{Turkey} and \textbf{Ham} and \textbf{RoastBeef} could go
into an array of type \textbf{Meat}. To do so, a designer could define
\textbf{Turkey} and \textbf{Ham} and \textbf{RoastBeef} as inheriting
from \textbf{Meat}.

Put another way, it's true Student3 has an idea about a relationship between entities that
is not specified in the code. The study authors focus only on the \emph{downside} of the idea: the
student fails to display a proper understanding of how arrays work in
Java. But, there
is also an upside of this idea. Because Student3 is thinking about
real-world propositions like turkey and ham being kinds of meat, they
might be prepared to appreciate and discuss an object-oriented way to
put turkey in a \textbf{Meat} array. But, that possibility is
speculative conjecture. We can't know for certain whether Student3 could
be tipped into a productive object-oriented design activity around the
meats example because that question was not a focus of the research.

My second example of research that criticizes students' non-canonical
understandings comes from Bonar and Soloway's 1983 study of Pascal
programmers \cite{bonar_uncovering_1983}, data from which is also analyzed and discussed in \cite{pea_languageindependent_1986}. A student in
\cite{bonar_uncovering_1983} was asked to ``Write a program which reads in
ten integers and prints the average of those integers'' (Bonar \&
Soloway, 1983, p. 12). In pseudo-code, she wrote:

\begin{verbatim}
Repeat
(1) Read a number (Num)
    (1a) Count := Count + 1
(2) Add the number to Sum
    (2a) Sum := Sum + Num
(3) until Count :=10
(4) Average := Sum div Num
(5) writeln ('average = ',Average)
\end{verbatim}

The interviewer then asked whether (1a) and (2a) were ``the same kinds
of statements.'' That interchange is reproduced here:

\begin{quote}
  Interviewer: Steps 1a and 2a: are those the same kinds of statements?

  Subject: How's that, are they the same \emph{kind}. Ahhh, ummm, not
  exactly, because with this {[}1a{]} you are adding - you initialize it
  at zero and you're adding one to it {[}points to the right side of 1a{]}
  which is just a constant kind of thing.

  Interviewer: Yes

  Subject: {[}points to 2a{]} Sum, initialized, to, uhh Sum to Sum plus
  Num, ahh - thats {[}points to left side of 2a{]} storing two values in
  one, two variables {[}points to Sum and Num on the right side of 2a{]}.
  That's {[}now points to 1a{]} a counter, that's what keeps the whole
  loop under control. Whereas, this thing {[}points to 2a{]} was probably
  the most interesting thing\ldots{}about Pascal when I hit it. That you
  could have the same, you sorta have the same thing here {[}points to
  1a{]}, it was interesting that you cold have, you could save space by
  having the Sum re-storing information on the left with two different
  things there {[}points to right side of 2a{]}, so I didn't need to have
  two. No, they're different to me.

  Interviewer: So - in summary, how do you think of 1a?

  Subject: I think of this {[}point to 1a{]} as just a constant, something
  that keeps the loop under control. And this {[}points to 2a{]} has
  something to do with something that you are gonna, that stores more
  kinds of information that you are going to take out of the loop with
  you. \cite{bonar_uncovering_1983}
\end{quote}


Pea and Kurland's interpretation? ``Here, again, we see the student believing
that the programming language knows more about her intentions than it
possibly can'' \cite{pea_cognitive_1983}.

As in Example 1, this student has an idea about relationships in code. Pea and Kurland
\cite{pea_cognitive_1983} see the \emph{downside} of her idea: believing PASCAL can understand
shades of programmer intent when, in fact, it cannot. And again, that
downside is real. It could cause trouble for this programmer later on if
she expects PASCAL to interpret her intent and it cannot.

In defense of the student, the question --- as asked --- is vague. Are
those statements the same \emph{to whom} and \emph{in what way?} Pea and Kurland
treat the data as though she meant ``the same to PASCAL.'' Indeed,
maybe she did, in which case his interpretation has traction. But,
another interpretation is that she meant to herself or to someone else
reading the code. Those statements might not be the same \emph{to her}
because she treats (1a) as having a function of controlling iteration
while (2a)'s job is to combine two numbers into a new sum.

These two purposes, which for the sake of description I'll call
\emph{keeping control} (1a) and \emph{totaling up} (2a) are, in a sense,
different. The PASCAL compiler (and runtime) does not differentiate
them, but humans can. And, humans may well \emph{want} to differentiate
them. diSessa (1986) describes exactly this kind of differentiation as a
consequence of separating the structural understanding of a programming
language from a functional understanding of a language. As an example,
he discusses the structure/function difference with respect to
variables:

\begin{quote}
  The structural aspects of a variable in a computer language are given
  primarily by the rules for setting their values and for getting access
  to their values. These rules apply in all contexts. In contrast, a
  variable's functions might vary. Sometimes they might be described as
  ``a flag'' or more generally, as ``a communications device.'' At other
  times a variable might function as ``a counter,'' ``data,'' or
  ``input.'' \cite{disessa_models_1986}
\end{quote}

The student in \cite{bonar_uncovering_1983} did not show evidence of
understanding the structural similarities between (1a) and (2a) in her
pseudo-code. And, those authors as well as others \cite{pea_cognitive_1983} justly insist that
similarity is important for students to understand. From a conceptual
standpoint, seeing the structural similarity constitutes a part of
``knowing'' PASCAL. But, even if knowing PASCAL were not the goal,
seeing the similarity helps one to take the perspective of a computing
agent that has no means for discerning programmer intent. Such
perspective-taking may help students avoid mistakes that arise from
over-assuming what a computer ``understands.''

The student did, however, show evidence of understanding a \emph{functional} \cite{disessa_models_1986} difference
between (1a) and (2a), but Pea and Kurland do not remark on that kind of
understanding at all. Both \cite{pea_cognitive_1983,bonar_uncovering_1983} also gloss over another
important difference: a programmer might not know in advance which
numbers are being passed in to the sum statement. So, in advance the
programmer can say nothing about how the value of \textbf{Sum} will
change as the loop iterates. In contrast, the programmer knows exactly
how the value of Count will change with each loop iteration. Again, we
claim this oversight is part of a subtle but observable trend in
programming misconceptions literature.

While, or perhaps because
research has been so preoccupied warring with students' problematic
knowledge, it has sometimes failed to recover the productive knowledge
(or resources for building it) students have. In Example 2, the
student already has a grasp that syntactically similar statements could
serve different conceptual purposes. And, that understanding could, in turn, shape how they program. The student might
invoke the $\Box=︎ \Box + 1$ syntactical
template (Or what Sherin would call ``symbol template'' \cite{sherin_how_2001}) when the situation seems to demand \emph{keeping control},
while invoking $\Box= ︎\Box + \mathrm{number}$ when \emph{totaling up} is the goal.
And, the idea that structurally similar symbol templates can serve
different functional and conceptual purposes fits precisely in line with both diSessa's distinction of structural/functional understanding of a programming language \cite{disessa_models_1986} and
Sherin's theory of symbolic forms \cite{sherin_how_2001}.

An example drives home the connection between \cite{disessa_models_1986} and \cite{sherin_how_2001} as it applies to programming. The symbolic
forms \emph{parts-of-a-whole} and \emph{base+change} have different
conceptual schemata. Parts-of-a-whole refers to the contributions of
component entities while base±change describes a kind of accumulation \cite{sherin_how_2001}.
Specifically, the terms in base±change ``contribute to a whole but play different roles. One is a base value; the other is a change to that base.'' But, the two distinct conceptual schemata share what I
would argue is the same symbolic structure: $\Box=︎ \Box + \Box$ (parts of a whole) and $\Box = \Box \pm \Delta$ (base + change) \cite{sherin_how_2001}.

The problem, for learning to program, comes in needing to fluidly
interpret and write code in languages that may demand incommensurable,
or at least distinct, conceptual schemata. As I show later in Table 4,
three current programming languages make remarkably different use of the
plus sign (+) as an operator. Crucially, some of the entailing ways to
make sense of how + works in those languages don't exist in Sherin's
(2001) catalog of conceptual schemata. In other words, I would argue
there are conceptual ways a \emph{programmer} may need to think about
interpreting or writing a $\Box=︎ \Box +\Box$ symbol template that even Sherin \cite{sherin_how_2001} doesn't
enumerate.One of the most obvious, for example, is the conceptual movement from seeing
  $\Box=︎ \Box +\Box$ as a statement of equality (typical in a math class) to seeing it as the assignment of a
  sum to a variable (typical in programming). To follow that implication, the canonical body of
knowledge about which programmers must reason is itself fractured,
because different languages design their operations around different
symbolic and conceptual metaphors.

To return to misconceptions, what seems to drive research on students'
misconceptions is computing education largely a need to get students to program computers
and reason about computation in ways that are canonically correct. And,
that's a worthwhile goals. But, as I've argued, we can
already identify cases where a narrow misconceptions focus is silent
about (at best) or dismissive of (at worst) students' useful intuitions. We identified
the further problems when a unilateral emphasis on one language's canon
opposes the vocabulary of symbolic forms (and diverse conceptual
schemata) expert programmers ultimately need. \emph{Taken in
total, that silence, dismissiveness, and narrow view of refining
knowledge perpetuates a deficit-focused discourse about student's
knowledge in computing.} A knowledge-deficiency perspective also fails to address what aspects of
students reasoning might get broken by attempts to ``fix'' such
``misconceptions''.

It's important to note that misconceptions research in computing didn't
always treat students' non-canonical knowledge as a problem. I begin the
next section by backtracing to some of the earliest work on students'
cognitive ``bugs''. There, we find researchers talking more explicitly
about what's useful in students' non-canonical knowledge---a stance
largely absent in modern computing misconceptions research.

\section{Core Arguments}\label{core-arguments}

\subsection{Not all cognitive programming bugs imply a problem with
the
student}\label{not-all-cognitive-programming-bugs-imply-a-problem-with-the-student}

What's curious about Pea and Kurland's \cite{pea_languageindependent_1986} comments on Bonar and Soloway \cite{bonar_uncovering_1983} is
that Pea's conclusions \cite{pea_languageindependent_1986} about Bonar and Soloway's data differed greatly from Bonar and Soloway's conclusions. Pea emphasized that when the student thought two
semantically-equivalent assignment statements in PASCAL were different,
it was a problem of egocentrism: ``students assume that there is
\emph{more} of their meaning for what they want to accomplish in the
program than is actually present in the code they have written'' \cite{pea_languageindependent_1986}. In other words, Pea treated the data as a fairly clear example of a
class of cognitive bugs. Specifically, he saw a bug class in which students simply
assumed the interpreter or runtime could infer programmer's shades
of intent.

Bonar and Soloway (1983), by contrast, were less quick to make
inferences either about the nature of the bug or the intervention
it entailed. Rather than jump to definitive conclusions, they were
circumspect:

\begin{quote}
  It is not clear exactly how to react to the bugs we have uncovered in
  novice understanding of programming. In some cases it may be appropriate
  to design new languages or constructs. Often, better instruction would
  take care of the problem. The intent of our studies is to better
  understand the source of the mismatches and misconceptions that cause
  novice bugs. Only once a bug is uncovered and understood are we ready to
  create a remedy for that bug. \cite{bonar_uncovering_1983}
\end{quote}

That Bonar and Soloway would even consider developing new constructs or
languages is a noteworthy distinction. Rather than assume wholesale that
students with ``bugs'' had wrong knowledge, the authors instead suppose
cognitive bugs have plausible origins worth designing around. Moreover,
they treat students' divergence from canon as \emph{an opportunity for
research to learn from students}. Precisely because students saw
functional differences (cf., diSessa, 1986) in semantically-equivalent
PASCAL statements, Bonar and Soloway (1983) reflect that perhaps
programming languages should be more expressive:

\begin{quote}
  We find it quite interesting that novices seem to understand the role or
  strategy of statements more clearly than the standard semantics. Such
  roles discussed here include ``counter variable,'' ``running total
  variable,'' ``running total loop,'' and ``first, then rest loop''. (See
  Soloway et al {[}1982b{]} for a detailed discussion of novice looping
  strategies.) Much work in programming languages is concerned with
  allowing a programmer to more accurately express his or her intentions
  in the program. Perhaps we can learn something from novices here - our
  programming systems should support recording the roles the programmer
  intends for various statements and variables. \cite{bonar_uncovering_1983}
\end{quote}

Again, what's noteworthy is that rather than treating students'
non-canonical views as a burden for instruction, Bonar and Soloway
instead see them as an opportunity for programming language designers to
make languages better.

That insight---that instruction and design can meet novices where they
are---carries through to their final remarks about studying and
analyzing novice programming knowledge:

\begin{quote}
  The experience and understanding of a novice are available for analysis.
  In particular, our results suggest that the knowledge people bring from
  natural language has a key effect on their early programming efforts.
  Our work suggests that we need serious study of the knowledge novices
  bring to a computing system. For most computerized tasks there is some
  model that a novice will use in his or her first attempts. We need to
  understand when it is appropriate to appeal to this model, and, when
  necessary, how to move a novice to some more appropriate model. (Bonar
  \& Soloway, 1983, p. 13)
\end{quote}

We assume Bonar and Soloway structured the final line of that quote deliberately. If
so, their phrasing has three consequences:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Appealing to novice's existing models gets precedence. That is,
  understanding how to leverage novices' existing knowledge comes first
  in research.
\item
  Changing the models novices have comes next, and explicitly ``when necessary.''
\item
  They speak of ``how to move a novice to some more appropriate model,''
  which does not necessarily entail rejecting a student's existing model, treating it as a misconception to be corrected, or otherwise ignoring what productive elements are present in a given novice model.
\end{enumerate}

We believe that taken together, these points convey a sense of how Bonar and Soloway \cite{bonar_uncovering_1983}
viewed learning and instruction in computing. Instruction explicitly
includes appeals to prior models and knowledge students might already
have. Learning, meanwhile, involves the movement \emph{when necessary}
to more appropriate models of computation. As we explain in the next
section, such a view of understanding and refining student ideas---in contrast to diagnosing the deficiencies in and replacement of student ideas---exactly aligns with a particular branch of
constructivism, where cognition is viewed as the complex activation of
manifold resources for thinking and knowing.

\subsection{Examples motivate the need for contextual-sensitivity in
modeling programming
cognition}\label{examples-motivate-the-need-for-contextual-sensitivity-in-modeling-programming-cognition}

Let's begin with two motivating examples. My aim with these examples is
to show how a practicing programmer might employ specific, distinct
conceptual models to reason locally about a piece of code. First,
consider variants of the PASCAL statements from Bonar and Soloway
(1983), where an assignment statement worked to increment a value and
store the result back to that value. In Table 2 below, I imagine five
different ways of writing a programming statement. Each of the five ways
is semantically equivalent to the others (or near enough for explanatory
purposes). And, in each example I add a layer of specificity to the
syntax. I also propose a corresponding interpretation of how I might
apply interpret and think about a given statement.\footnote{I assume for
  simplicity's sake that all variables and functions in my code samples
  evaluate to floating-point numbers that can be combined under
  addition. I also assume, crucially, that all statements are in the
  same hypothetical language and that the variable names connote nothing
  to the computational interpreter.}

\protect\hypertarget{ux5fToc252445956}{}{}Table -- Five different
interpretations of semantically equivalent programming statements in the
same language

\begin{center}
  \begin{tabular}{ | l | l |}
    1 & \texttt{x\ =\ x\ +\ d} \\
    2 & \texttt{x\ =\ x\ +\ update} \\
    3 & \texttt{x\_position\ =\ x\_position\ +\ update} \\
    4 & \texttt{x\_position\ =\ x\_position\ +\ update(t)} \\
    5 & \texttt{x\_position\ =\ x\_position\ +\ update(...)} \\
  \end{tabular}
\end{center}


I stress that the third column is about \emph{how I might think about}
each programming statement\emph{.} By no means am I making normative
claims about how one \emph{ought} to think about it, or whether the
statement actually does what its names might suggest it does. Rather,
``How I might think about it'' reflects the kind of local meaning or
interpretation I might attach to such a statement when I work with it,
given my understanding of its role and context.

Consider specifically statements 1 and 4. Statement 1 could very well be
an incrementer in some kind of iterative code. If I had to debug code
that employs statement 1, what I might do is exploit my knowledge of
what d is (does it hold a constant value? Is it 1?) and try inserting
intermediate print statements into the iterative code. Doing so, I can
inspect textually how values change with each iteration. In statement
4's case, it could very well be that the position-update code animates
images on a screen. If there's a problem with that code, one of the
easiest ways I might notice is that the acceleration seems off in the
graphics. Consequently, my debugging might call upon knowledge I have
from kinematics. I might try inserting code that draws a dot at the
object's on-screen position with each iteration, leaving a trail I can
visually inspect. I could then look at the path of the object's
trajectory and the spacing patterns between successive dots as a
first-pass test of whether my code achieves the motion I want.

To be clear, it's not just that graphics might improve my efficiency in
debugging a statement. Rather, applying an interpretive frame that
treats an assignment statement as a kinematic position update lets me
\emph{use conceptual knowledge from physics} to diagnose and fix
problems in my code. If I view the assignment statement as saying
something about the motion of an object (cf., Hammer, 1994, p. 165), a
field of knowledge and concomitant techniques from physics becomes
available to me to think with. But, if I focus only on the
semantic-level equivalence of statements 1 through 5, there would be no
obvious reason for me to access what I know about physics in order to
reason about the code.

My second example concerns statements that are syntactically-similar,
rather than semantically-similar. I proposed that the statements in
Table 2 all came from the same language. But, another phenomenon comes
into play when different languages use the same symbology for
conceptually different operations. Table 3 shows examples of what look
like semantically-equivalent operations, but in fact are not.

\protect\hypertarget{ux5fToc252445957}{}{}Table -- Three
syntactically-similar statements with very different semantics

% \begin{supertabular}[]{@{}llll@{}}
% \toprule
% \textbf{Statement } & Programming Syntax & Language & How I think about
% it\tabularnewline
% \midrule
% \endhead
% \textbf{1} & i = i + 1 & C & \textbf{Increments} i by 1\tabularnewline
% \textbf{2} & w = w + ``ly'' & JavaScript & \textbf{Appends} ``ly'' to
% the string w\tabularnewline
% \textbf{3} & p = p + geom\_point() & R (ggplot2) & \textbf{Composes} a
% layer of points onto a plot p\tabularnewline
% \bottomrule
% \end{supertabular}

The catch here is that the plus operator takes on different roles in
different languages because of how those languages define its use.
Statement 1 increments a number in C; Statement 2 appends the letters
``ly'' to a string; Statement 3 adds a layer of points to a statistical
graphics plot. These different kinds of operations become even more
apparent and consequential when, for example, such statements are
repeated. In the R/ggplot2 code below,\footnote{In R, the assignment
  operator can be written as a directional arrow. The symbol
  \textless{}- (``less-than, hyphen'') indicates the value on the right
  side of the symbol is being assigned to the variable on the left side
  of the symbol. As used, the symbol itself is semantically equivalent
  to having written an equals sign (``=``).} I'm using multiple
reassignment statements to compose a statistical graphics plot. The
layered creation of a plot invites a very different kind of conceptual
interpretation than, say, repeatedly accumulating numbers into a running
sum:

p \textless{}- InitializeGgplot\_1w()

p \textless{}- p + GrandMeanLine(owp)

p \textless{}- p + GrandMeanPoint(owp)

p \textless{}- p + ScaleX\_1w(owp)

p \textless{}- p + ScaleY\_1w(owp)

p \textless{}- p + JitteredScoresByGroupContrast(owp, jj)

One obvious reason for thinking about this code with a different
interpretive frame is that numeric addition is commutative; composing a
plot is not necessarily commutative.\footnote{To convince yourself that
  plot composition isn't commutative, imagine a scale function that
  squares up the aspect ratio of a plot and another scale function that
  sets the aspect ratio to 1.5:1. Applying the square function last
  produces a square plot; applying it first produces a rectangular plot.
  String concatenation is also not necessarily commutative. ``cat'' +
  ``dog'' evaluates to ``catdog,'' while ``dog'' + ``cat'' evaluates to
  ``dogcat.''} So, despite the syntactic similarity, reassignments that
compose a plot using reassignment (as above) does not obey the same
rules as reassignments for a running total. But, even within this code
block, statements that look alike perform operations of a different
nature. While some expressions (e.g, ``+ GrandMeanLine(owp)'') add a
visual layer to a plot, others modify features of the plot (e.g, ``+
Scale\_X(owp)'', which adjusts the scales on the plot's x-axis to fit
the numeric range of the data).

Given these motivating examples, it seems sensible to think there's
utility in a programmer having different conceptual metaphors available
to think about and work with code. Example 1 shows that choosing to
apply knowledge from physics to a piece of code can change the cognitive
nature of debugging. There, debugging a position-update statement
becomes, in part, reasoning kinematically about the properties of motion
trails.\footnote{For comparison, consider the argument that ringing an
  aircraft speedometer with physical markers changes the nature of
  cognition when pilots work to land a plane (Hutchins, 1995b).} Example
2 shows that across languages, programmers might have to deploy
different conceptual metaphors to reason about statements in a
locally-consistent way. Knowing that plots in ggplot2 can be composed
layer-by-layer with reassignment is crucial if you're trying to write or
understand code that creates statistical graphics. But, I would argue
that thinking about $\Box = \Box + \Box$ as ``compose new layer onto plot'' can and
does appeal to different kinds of knowledge when compared to thinking
about $\Box = \Box + \Box$ as ``include this addend in the sum,'' which itself can
and does appeal to different kinds of concepts when compared to thinking
about $\Box = \Box + \Box$ as ``increment the counter.''

Stepping back, I can build the following argument

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Programming can be helped by applying conceptual models to code,
  particularly when relevant domain-knowledge structures can
  advantageously transform a problem (example 1)
\item
  But, conceptual models don't work all the time for all statements.
  Because languages are designed differently, the same syntax can
  actually correspond to very different operations in code (example 2).
  And, that's true both within and across languages.
\item
  Consequently, it makes less sense to treat conceptual models as right
  or wrong, and more sense to treat them as differentially advantageous
  for thinking about what a piece of code does. (Thinking a ``+''
  implies numerical addition isn't \emph{globally wrong} in JavaScript,
  but it won't explain why 1 + ``1'' yields ``11'' as a result.)
\item
  It seems plausible that successful programmers, when reasoning about
  or writing code, are able to dynamically access or deploy conceptual
  models that are advantageous given the context (language, syntax,
  surrounding code). Certainly such a supposition is in line with work
  suggesting students have resources for thinking conceptually and
  dynamically about how mathematics models real-world situations (Izsák,
  2004; Sherin, 2001)
\item
  To model how programmers think with conceptual models, a suitable
  framework should be able to account for the dynamic, context-sensitive
  deployment of conceptual knowledge.
\item
  To model how programmers develop expertise, a suitable framework
  should be able to describe higher-order phenomena. Such phenomena
  include explaining how programmers come to have conceptual models or
  generate new ones, why they decide to deploy them, and how programmers
  consider which conceptual model (i.e., which way to think about code)
  is appropriate.
\end{enumerate}

Taken together, these assertions propose criteria for how we might
strive to model cognition in programming. Our modeling frameworks should
be context-dependent, dynamic, and capable of explaining where
conceptual models come from. They should also be able to account for
phenomena that are not themselves conceptual, including what directs the
use of certain kinds of conceptual knowledge. In the learning sciences,
such models already exist and have proven useful and productive for
thinking about thinking.

\subsection{Manifold models of cognition explain context-dependence
and the growth of
expertise}\label{manifold-models-of-cognition-explain-context-dependence-and-the-growth-of-expertise}

In 1993, a pair of articles in the learning sciences staked a strong
claim for viewing knowledge as a network of pieces, isolated enough to
be locally triggered but trainable enough to fire in larger concerted
patterns (diSessa, 1993; Smith, diSessa, \& Roschelle, 1993). Informed
in part by agent-based accounts of cognition (Minsky, 1986) and complex
systems models (diSessa, 2002), the central tenets of an ``in-pieces''
approach hold that knowledge is emergent from interacting primitives,
rather than unitary and monolithic. An example from Smith, diSessa, and
Roschelle helps illustrate the point.

The authors show that we might think of a rubber band as a different
conceptual entity depending on context. In several different
situations---wrapped around a newspaper, pulled taut as a string, spun
to store energy in a toy plane propeller---we intuitively think about
the rubber band's physical behavior differently: one as a negligible
part of the newspaper's point mass, another as a transverse pendulum
(likely) obeying Hooke's Law, and the third as a torsional spring. Those
differences in intuitive thinking reflect the contextual dependency of
what we know about the physical world:

In each of the rubberband examples, various pieces of intuitive physical
knowledge describe the mechanism at work: the rubber band binds the
newspaper, grips the jar lid, and acts a source of springiness for the
bobbing object. Although a mapping cannot be made from the rubberband to
scientific entities, it is quite easy to map these qualitatively
distinct physical processes to scientific entities and laws. For
example, instances of binding almost always map to a practically rigid
body. Likewise, gripping maps to friction forces, and springiness maps
to Hooke's law. This suggests that applicability can depend directly on
our intuitive knowledge---knowledge that exists prior to any formal
scientific training (Smith et al., 1993, p. 144).

The in-pieces approach to modeling cognition has been used, among other
things, to explain how experts reason about fractions and decimals
(Smith et al., 1993), how students reason about forces in physics
(diSessa \& Sherin, 1998; diSessa, 1993; Hammer, 1996; Sherin, 2001),
how students construct and evaluate algebraic representations of
physical situations (Izsák, 2004), and how knowledge transfers across
contexts (Hammer et al., 2005; Wagner, 2006). Because its starting
assumption is that knowledge is fragmented, knowledge-in-pieces can
account for wide variations of how people---particularly novices---use
knowledge on a moment-to-moment basis. In other words, because it
assumes knowledge is local, it can still explain the kinds of
globally-inconsistent ways people might reason about physical situations
(diSessa, 1993). As a framework, an in-pieces approach ultimately argues
that models of concept replacement and good/bad criteria for knowledge
should be supplanted by a learning model of alignment/refinement of
prior knowledge and the consideration of knowledge as
productive/unproductive.

Hammer and colleagues have worked to extend the in-pieces approach to
explain how students' epistemological activity---how they orient toward
knowledge and knowing in a context (Hammer et al., 2005; Hammer \& Elby,
2002, 2003). Specifically, those authors use two core theoretical
constructs to explain students' stances toward knowledge and knowing:

\begin{itemize}
\item
  \emph{Epistemological Resources} are the epistemological equivalent of
  diSessa's phenomenological primitives (p-prims). Resources, the
  authors propose, are the atomic units involved in how people cognize
  about the source of knowledge, the nature of knowledge, and
  epistemological activities (Hammer \& Elby, 2003; Louca, Elby, Hammer,
  \& Kagey, 2004).
\item
  \emph{Epistemological Frames} are the emergent result of subsets of
  resources acting in concert. Drawing from both Goffman's (1974)
  sociological notion of frame as structures of expectations and
  subsequent work on framing in discourse (Tannen, 1993),
  epistemological frames are a participant's local answer to the
  question ``what is it {[}specifically, what knowledge activity{]}
  that's going on here'' (Goffman, 1974, p. 8).
\end{itemize}

Resources can frames can interact in activity settings to produce
larger-scale patterns called ``epistemological coherences'' (Rosenberg,
Hammer, \& Phelan, 2006) where evidence from data suggests that a
network of discrete cognitive units can nonetheless give rise to stable
cognition.



An example helps ground this in-pieces approach to epistemology. In
Russ, Coffey, Hammer, and Hutchison (2008), the authors describe the
situation where an elementary student reasons about why an empty juice
box collapses when you suck on the straw. One student gives what the
authors deem to be an excellent mechanistic account of why the juice box
collapses. But, as the teacher seems to steer the discussion toward
vocabulary---in this case, ``pressure''---the student clearly pulls back
from her mechanistic reasoning, seems much more diffident, and claims
that pressure is hard to explain. That example highlights the disconnect
between doing science as knowing vocabulary and doing science as
reasoning mechanistically. Moreover, it strikingly highlights that a
student who by all accounts produced an excellent explanation of how
pressure works was left nonetheless with the impression that pressure
was hard to explain.\footnote{In fairness to the teacher, I'm trying to
  focus on the result of the interaction and far less on the intent the
  teacher might have had. The student still left with a sense that
  science might be about vocabulary, even if that's not the view the
  teacher would espouse or was trying to enact in the moment.}

\subsection{Acknowledgments}\label{acknowledgments}

Blinded for review.

\clearpage

\bibliographystyle{acm}
\bibliography{bibliography}

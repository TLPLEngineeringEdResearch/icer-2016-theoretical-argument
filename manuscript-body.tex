\section{Abstract}\label{Abstract}

This paper aims to expand our sense of what's possible in modeling cognition within computing education research. We argue that research
approaches that privilege canonical knowledge do so at the
expense of other productive knowledge and ways of knowing that students
have. We explore applicable cognitive theory by showing how distributed cognition and symbolic forms can be a powerful framework for analysis in CSEd. Finally, we conclude with an exploration of epistemological concerns, arguing that a fundamental concern for our research community should be paying attention to what counts as \texttt{knowledge} and \texttt{knowing} in computing learning environments.

\section{Introduction}\label{Introduction}

Science and math education started challenging misconception models of mind in 1993 \cite{disessa_epistemology_1993,smith_misconceptions_1993}. By 1996, learning scientists were boldly repudiating the assumptions of misconceptions: ``Not all thoughts students express need to be understood as directly reflecting stable, stored knowledge structures. What the misconceptions perspective treats as a stored construct may alternatively be treated as an act of construction.'' \cite{hammer_misconceptions_1996}. In the more than 20 years since those papers were published, researchers---particularly in science education---have pushed cognitive models beyond the static assumptions of classical misconception accounts of knowledge. But, a preponderance of research in computing education (CSEd) has modeled and continues to model cognition through misconceptions. Such research assumes students have entrenched, wrong ideas about computation. And, while misconceptions research in computing education has advanced our understanding of teaching and learning, its narrow focus also begets problems that are growing too big to ignore:

\begin{enumerate}
  \tightlist
  \item When we use misconceptions to treat student ideas as right or wrong, we establish and perpetuate a deficit model of student understanding.
  \item The more classical misconceptions-based research we publish as a community, the stronger that deficit narrative becomes in our discourse.
\end{enumerate}

This paper aims squarely at those problems by expanding a sense of what's possible in modeling cognition within computing education research. We argue research
approaches that inflexibly privilege canonical knowledge do so at the
expense of other productive knowledge and ways of knowing that students
have. First, we reanalyze prior data to show how we might recast misconceptions as the potential seeds of productive knowledge. We then argue through example that expertise in programming can involve the fluid and active construction of conceptual metaphors to deal with idiosyncrasies within and across programming languages. These examples help broaden our sense of applicable cognitive theory by showing how distributed cognition and symbolic forms can be a powerful framework for analysis in CSEd. Finally, we conclude with an exploration of epistemological concerns, arguing that a fundamental concern for our research community should be paying attention to what counts as \texttt{knowledge} and \texttt{knowing} in computing learning environments.

\subsection{Misconceptions research in computing education tends to
ignore students' productive
knowledge}\label{misconceptions-research-in-computing-education-tends-to-ignore-students-productive-knowledge}



In the past three decades, educational research has had a marked focus
on students' misconceptions in programming. It's a focus with a sensible
origin. Students get things wrong in programming --- often
systematically so --- and in ways that seem resistant to instruction.
The cause of those errors is theorized to be something cognitive,
whether it's a ``bug'' \cite{pea_buggy_1987,pea_languageindependent_1986,vanlehn_mind_1990}, a
``misconception'' \cite{bayman_diagnosis_1983,bonar_preprogramming_1985,clancy_misconceptions_2004,gal-ezer_efficiency_2004,herman_proof_2008,kaczmarczyk_identifying_2010}, a ``belief'' \cite{fleury_student_1993}, or a ``student-constructed
rule'' \cite{fleury_parameter_1991,fleury_programming_2000} in programming. Instruction, Clancy argues, should try to identify,
address, and correct these misconceptions because they
can represent barriers to learning \cite{clancy_misconceptions_2004}.

How that line of thinking and research becomes problematic is two-fold.
First, when taken in total the alleged brokenness of student knowledge
begins eclipsing all else in studying the cognition of learning to
program. In other words, most cognitively-focused educational research
in computer science treats students as having varied degrees of
deficiency with respect to canonical knowledge. Below is an unordered,
partial sampling of topics about which researchers have documented
students' misconceptions. Note across the list the variation in both the
grain sizes of students' misconceptions and the programming languages in
which they manifest:

\begin{itemize}
\tightlist
\item
  Objects in object-oriented programming \cite{holland_avoiding_1997}
\item
  Algorithms and data structures \cite{danielsiek_detecting_2012,paul_hunting_2013}
\item
  Programming statements in BASIC \cite{bayman_diagnosis_1983}
\item
  Programming in Java \cite{fleury_programming_2000}
\item
  Programming in Pascal \cite{fleury_student_1993}
\item
  Parameter-passing \cite{fleury_parameter_1991}
\item
  Arrays in Java \cite{kaczmarczyk_identifying_2010}
\item
  Objects in Java \cite{kaczmarczyk_identifying_2010}
\item
  Algorithms and computational complexity \cite{trakhtenbrot_students_2013}
\item
  Boolean logic \cite{herman_proof_2008}
\item
  The efficiency of algorithms \cite{gal-ezer_efficiency_2004}
\item
  The Build-Heap algorithm \cite{seppala_observations_2006}
\item
  Hashtables \cite{patitsas_countably_2013}
\item
  The correctness of programs \cite{kolikant_my_2008}
\item
  Polynomial and mapping reduction in the Theory and Computation of Complexity \cite{gal-ezer_identification_2016}
\end{itemize}

Clancy \cite{clancy_misconceptions_2004} provides a comprehensive overview of this line of
research, though in the past decade it has only grown. Indeed, roughly
half the articles above were published in the ten years since Clancy's
overview.

Identifying and removing barriers to student learning seems like a good
thing. So, it should follow that cataloging student misconceptions and
developing remedies for them should also be a good thing. But, the
logical implication isn't that clean. In some cases students display
productive, useful knowledge that's either ignored or outright
criticized by researchers. Aligning students toward canonical knowledge
makes sense, but doing so at the expense of---or in direct contradiction
to---useful ways of knowing seems undesirable at best. Next, we expand on
two examples from misconceptions research in programming. Specifically,
we show how and why we think a misconceptions focus in programming casts
aside students' useful intuitions and understandings.

The first example comes from \cite{kaczmarczyk_identifying_2010}. Part of that
study involved giving students snippets of Java code and asking students
to diagram (or pseudo-code) how the information would be stored in
memory. Below we have reproduced the code for Problem 2:

\hypertarget{sandiwches-code}{\label{sandwiches-code}}
\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{Cheese[] cheeses = }\KeywordTok{new} \NormalTok{Cheese[}\DecValTok{4}\NormalTok{];}
\NormalTok{Meat[] meats = }\KeywordTok{new} \NormalTok{Meat[}\DecValTok{2}\NormalTok{];}
\NormalTok{Turkey turkey;}
\NormalTok{Ham ham;}
\NormalTok{RoastBeef roastBeef;}
\DataTypeTok{boolean} \NormalTok{lettuce = }\KeywordTok{true}\NormalTok{;}
\DataTypeTok{boolean} \NormalTok{tomato = }\KeywordTok{true}\NormalTok{;}
\NormalTok{SauceType sauceType = }\KeywordTok{new} \FunctionTok{SauceType}\NormalTok{();}
\DataTypeTok{int} \NormalTok{numMeat;}
\DataTypeTok{int} \NormalTok{numCheese;}
\end{Highlighting}
\end{Shaded}

In diagramming this information, a student in the study makes a mistake:

\begin{quote}
  Student3 makes incorrect assumptions about connections between variables
  to the extent that the student makes a mistake concerning the types of
  the variables. As a result, the student places Objects of different
  types in an array whose type matches none of them: ``And so because
  there's two arrays, cheese and meats, uh, all those turkey and ham and
  roast beef are gonna be sorted into the meats array.'' \cite{kaczmarczyk_identifying_2010}
\end{quote}

The researchers are correct in the sense that \texttt{turkey} and
\texttt{ham} and \texttt{roastBeef} will \emph{not} be sorted into the
\texttt{meats} array. First, there is no code here that places
\texttt{turkey} and \texttt{ham} and \texttt{roastBeef} in the array;
there is only code that
declares them as variables. Moreover, as written, an attempt to place
\texttt{turkey} and \texttt{ham} and \texttt{roastBeef} into the array
would fail. Because of type restrictions in Java, only objects of class
\texttt{Meat} (or objects that inherit from class \texttt{Meat}) can go in the array.
\texttt{turkey} and \texttt{ham} and \texttt{roastBeef} are, perhaps
confusingly, references to object instances of classes \texttt{Turkey}
and \texttt{Ham} and \texttt{RoastBeef}, so in the current snippet they
cannot enter an array of type \texttt{Meat} because (1) they don't yet
exist as objects and (2) even if they did exist, their types don't match
the array's type. The authors call this misconception \emph{semantics to
semantics}, which occurs ``when the student inappropriately
assume{[}s{]} details about the relationship and operation of code
samples, although such information was neither given nor implied''
\cite{kaczmarczyk_identifying_2010}.

Again, the researchers are right that the student is failing to describe
the code in a way consistent with canon. But, in their non-canonical thinking Student3 evidences
potentially ``\emph{productive}'' \cite{hammer_form_2002,hammer_tapping_2003} insights about design. Precisely \emph{because}
there is no code stating that \texttt{turkey} and \texttt{roastBeef} and
\texttt{ham} are sorted into the array, the student is \emph{inferring} that to
be true. And, while that behavior is not what's happening, it
\emph{would} be sensible to design a program where specific instances of
classes \texttt{Turkey} and \texttt{Ham} and \texttt{RoastBeef} could go
into an array of type \texttt{Meat}. To do so, a designer could define
\texttt{Turkey} and \texttt{Ham} and \texttt{RoastBeef} as inheriting
from \texttt{Meat}.

Put another way, it's true Student3 has an idea about a relationship between entities that
is not specified in the code. The study authors focus only on the \emph{downside} of the idea: the
student fails to display a proper understanding of how arrays work in
Java. But, there
is also an upside of this idea. Because Student3 is thinking about
real-world propositions like turkey and ham being kinds of meat, they
might be prepared to appreciate and discuss an object-oriented way to
put turkey in a \textbf{Meat} array. But, that possibility is
speculative conjecture. We can't know for certain whether Student3 could
be tipped into a productive object-oriented design activity around the
meats example because that question was not a focus of the research.

Our second example of research that criticizes students' non-canonical
understandings comes from Bonar and Soloway's 1983 study of Pascal
programmers \cite{bonar_uncovering_1983}, data from which is also analyzed and discussed in \cite{pea_languageindependent_1986}. A student in
\cite{bonar_uncovering_1983} was asked to ``Write a program which reads in
ten integers and prints the average of those integers'' (Bonar \&
Soloway, 1983, p. 12). In pseudo-code, she wrote:

\begin{verbatim}
Repeat
(1) Read a number (Num)
    (1a) Count := Count + 1
(2) Add the number to Sum
    (2a) Sum := Sum + Num
(3) until Count :=10
(4) Average := Sum div Num
(5) writeln ('average = ',Average)
\end{verbatim}

The interviewer then asked whether (1a) and (2a) were ``the same kinds
of statements.'' That interchange is reproduced here:

\begin{quote}
  Interviewer: Steps 1a and 2a: are those the same kinds of statements?

  Subject: How's that, are they the same \emph{kind}. Ahhh, ummm, not
  exactly, because with this {[}1a{]} you are adding - you initialize it
  at zero and you're adding one to it {[}points to the right side of 1a{]}
  which is just a constant kind of thing.

  Interviewer: Yes

  Subject: {[}points to 2a{]} Sum, initialized, to, uhh Sum to Sum plus
  Num, ahh - thats {[}points to left side of 2a{]} storing two values in
  one, two variables {[}points to Sum and Num on the right side of 2a{]}.
  That's {[}now points to 1a{]} a counter, that's what keeps the whole
  loop under control. Whereas, this thing {[}points to 2a{]} was probably
  the most interesting thing\ldots{}about Pascal when I hit it. That you
  could have the same, you sorta have the same thing here {[}points to
  1a{]}, it was interesting that you cold have, you could save space by
  having the Sum re-storing information on the left with two different
  things there {[}points to right side of 2a{]}, so I didn't need to have
  two. No, they're different to me.

  Interviewer: So - in summary, how do you think of 1a?

  Subject: I think of this {[}point to 1a{]} as just a constant, something
  that keeps the loop under control. And this {[}points to 2a{]} has
  something to do with something that you are gonna, that stores more
  kinds of information that you are going to take out of the loop with
  you. \cite{bonar_uncovering_1983}
\end{quote}


Pea and Kurland's interpretation? ``Here, again, we see the student believing
that the programming language knows more about her intentions than it
possibly can'' \cite{pea_cognitive_1983}.

As in Example 1, this student has an idea about relationships in code. Pea and Kurland
\cite{pea_cognitive_1983} see the \emph{downside} of her idea: believing PASCAL can understand
shades of programmer intent when, in fact, it cannot. And again, that
downside is real. It could cause trouble for this programmer later on if
she expects PASCAL to interpret her intent and it cannot.

In defense of the student, the question --- as asked --- is vague. Are
those statements the same \emph{to whom} and \emph{in what way?} Pea and Kurland
treat the data as though she meant ``the same to PASCAL.'' Indeed,
maybe she did, in which case his interpretation has traction. But,
another interpretation is that she meant to herself or to someone else
reading the code. Those statements might not be the same \emph{to her}
because she treats (1a) as having a function of controlling iteration
while (2a)'s job is to combine two numbers into a new sum.

These two purposes, which for the sake of description we'll call
\emph{keeping control} (1a) and \emph{totaling up} (2a) are, in a sense,
different. The PASCAL compiler (and runtime) does not differentiate
them, but humans can. And, humans may well \emph{want} to differentiate
them. diSessa (1986) describes exactly this kind of differentiation as a
consequence of separating the structural understanding of a programming
language from a functional understanding of a language. As an example,
he discusses the structure/function difference with respect to
variables:

\begin{quote}
  The structural aspects of a variable in a computer language are given
  primarily by the rules for setting their values and for getting access
  to their values. These rules apply in all contexts. In contrast, a
  variable's functions might vary. Sometimes they might be described as
  ``a flag'' or more generally, as ``a communications device.'' At other
  times a variable might function as ``a counter,'' ``data,'' or
  ``input.'' \cite{disessa_models_1986}
\end{quote}

The student in \cite{bonar_uncovering_1983} did not show evidence of
understanding the structural similarities between (1a) and (2a) in her
pseudo-code. And, those authors as well as others \cite{pea_cognitive_1983} justly insist that
similarity is important for students to understand. From a conceptual
standpoint, seeing the structural similarity constitutes a part of
``knowing'' PASCAL. But, even if knowing PASCAL were not the goal,
seeing the similarity helps one to take the perspective of a computing
agent that has no means for discerning programmer intent. Such
perspective-taking may help students avoid mistakes that arise from
over-assuming what a computer ``understands.''

The student did, however, show evidence of understanding a \emph{functional} \cite{disessa_models_1986} difference
between (1a) and (2a), but Pea and Kurland do not remark on that kind of
understanding at all. Both \cite{pea_cognitive_1983,bonar_uncovering_1983} also gloss over another
important difference: a programmer might not know in advance which
numbers are being passed in to the sum statement. So, in advance the
programmer can say nothing about how the value of \textbf{Sum} will
change as the loop iterates. In contrast, the programmer knows exactly
how the value of Count will change with each loop iteration. Again, we
claim this oversight is part of a subtle but observable trend in
programming misconceptions literature.

While, or perhaps because
research has been so preoccupied warring with students' problematic
knowledge, it has sometimes failed to recover the productive knowledge
(or resources for building it) students have. In Example 2, the
student already has a grasp that syntactically similar statements could
serve different conceptual purposes. And, that understanding could, in turn, shape how they program. The student might
invoke the $\Box=︎ \Box + 1$ syntactical
template (Or what Sherin would call ``symbol template'' \cite{sherin_how_2001}) when the situation seems to demand \emph{keeping control},
while invoking $\Box= ︎\Box + \mathrm{number}$ when \emph{totaling up} is the goal.
And, the idea that structurally similar symbol templates can serve
different functional and conceptual purposes fits precisely in line with both diSessa's distinction of structural/functional understanding of a programming language \cite{disessa_models_1986} and
Sherin's theory of symbolic forms \cite{sherin_how_2001}.

An example drives home the connection between \cite{disessa_models_1986} and \cite{sherin_how_2001} as it applies to programming. The symbolic
forms \emph{parts-of-a-whole} and \emph{base+change} have different
conceptual schemata. Parts-of-a-whole refers to the contributions of
component entities while \emph{base+change} describes a kind of accumulation \cite{sherin_how_2001}.
Specifically, the terms in \emph{base+change} ``contribute to a whole but play different roles. One is a base value; the other is a change to that base.'' But, the two distinct conceptual schemata share what we
would argue is the same symbolic structure: $\Box=︎ \Box + \Box$ (parts of a whole) and $\Box = \Box \pm \Delta$ (base + change) \cite{sherin_how_2001}.

The problem, for learning to program, comes in needing to fluidly
interpret and write code in languages that may demand incommensurable,
or at least distinct, conceptual schemata. As we show later in Table 4,
three current programming languages make remarkably different use of the
plus sign (+) as an operator. Crucially, some of the entailing ways to
make sense of how + works in those languages don't exist in Sherin's
(2001) catalog of conceptual schemata. In other words, we would argue
there are conceptual ways a \emph{programmer} may need to think about
interpreting or writing a $\Box=︎ \Box +\Box$ symbol template that even Sherin \cite{sherin_how_2001} doesn't
enumerate.One of the most obvious, for example, is the conceptual movement from seeing
  $\Box=︎ \Box +\Box$ as a statement of equality (typical in a math class) to seeing it as the assignment of a
  sum to a variable (typical in programming). To follow that implication, the canonical body of
knowledge about which programmers must reason is itself fractured,
because different languages design their operations around different
symbolic and conceptual metaphors.

To return to misconceptions, what seems to drive research on students'
misconceptions in computing education is largely a need to get students to program computers
and reason about computation in ways that are canonically correct. And,
that's a worthwhile goal. But, as we've argued, we can
already identify cases where a narrow misconceptions focus is silent
about (at best) or dismissive of (at worst) students' useful intuitions. We identified
the further problems when a unilateral emphasis on one language's canon
opposes the vocabulary of symbolic forms (and diverse conceptual
schemata) expert programmers ultimately need. \emph{Taken in
total, that silence, dismissiveness, and narrow view of refining
knowledge perpetuates a deficit-focused discourse about student's
knowledge in computing.} A knowledge-deficiency perspective also fails to address what aspects of
students reasoning might get broken by attempts to ``fix'' such
``misconceptions''.

It's important to note that misconceptions research in computing didn't
always treat students' non-canonical knowledge as a problem. We begin the
next section by backtracing to some of the earliest work on students'
cognitive ``bugs''. There, we find researchers talking more explicitly
about what's useful in students' non-canonical knowledge---a stance
largely absent in modern computing misconceptions research.

\section{Core Arguments}\label{core-arguments}

\subsection{Not all cognitive programming bugs imply a problem with
the
student}\label{not-all-cognitive-programming-bugs-imply-a-problem-with-the-student}

What's curious about Pea and Kurland's \cite{pea_languageindependent_1986} comments on Bonar and Soloway \cite{bonar_uncovering_1983} is
that Pea's conclusions \cite{pea_languageindependent_1986} about Bonar and Soloway's data differed greatly from Bonar and Soloway's conclusions. Pea emphasized that when the student thought two
semantically-equivalent assignment statements in PASCAL were different,
it was a problem of egocentrism: ``students assume that there is
\emph{more} of their meaning for what they want to accomplish in the
program than is actually present in the code they have written'' \cite{pea_languageindependent_1986}. In other words, Pea treated the data as a fairly clear example of a
class of cognitive bugs. Specifically, he saw a bug class in which students simply
assumed the interpreter or runtime could infer programmer's shades
of intent.

Bonar and Soloway (1983), by contrast, were less quick to make
inferences either about the nature of the bug or the intervention
it entailed. Rather than jump to definitive conclusions, they were
circumspect:

\begin{quote}
  It is not clear exactly how to react to the bugs we have uncovered in
  novice understanding of programming. In some cases it may be appropriate
  to design new languages or constructs. Often, better instruction would
  take care of the problem. The intent of our studies is to better
  understand the source of the mismatches and misconceptions that cause
  novice bugs. Only once a bug is uncovered and understood are we ready to
  create a remedy for that bug. \cite{bonar_uncovering_1983}
\end{quote}

That Bonar and Soloway would even consider developing new constructs or
languages is a noteworthy distinction. Rather than assume wholesale that
students with ``bugs'' had wrong knowledge, the authors instead suppose
cognitive bugs have plausible origins worth designing around. Moreover,
they treat students' divergence from canon as \emph{an opportunity for
research to learn from students}. Precisely because students saw
functional differences in semantically-equivalent
PASCAL statements, Bonar and Soloway \cite{bonar_uncovering_1983} reflect that perhaps
programming languages should be more expressive:

\begin{quote}
  We find it quite interesting that novices seem to understand the role or
  strategy of statements more clearly than the standard semantics. Such
  roles discussed here include ``counter variable,'' ``running total
  variable,'' ``running total loop,'' and ``first, then rest loop''. (See
  Soloway et al {[}1982b{]} for a detailed discussion of novice looping
  strategies.) Much work in programming languages is concerned with
  allowing a programmer to more accurately express his or her intentions
  in the program. Perhaps we can learn something from novices here - our
  programming systems should support recording the roles the programmer
  intends for various statements and variables. \cite{bonar_uncovering_1983}
\end{quote}

Again, what's noteworthy is that rather than treating students'
non-canonical views as a burden for instruction, Bonar and Soloway
instead see them as an opportunity for programming language designers to
make languages better. Indeed, an empirical approach to language design has recently been articulated in Stefik and Siebert's work regarding language syntax's effect on novices. \cite{stefik_intuitive_2011}

That insight---that instruction and design can meet novices where they
are---carries through to Bonar and Soloway's final remarks about studying and
analyzing novice programming knowledge:

\begin{quote}
  The experience and understanding of a novice are available for analysis.
  In particular, our results suggest that the knowledge people bring from
  natural language has a key effect on their early programming efforts.
  Our work suggests that we need serious study of the knowledge novices
  bring to a computing system. For most computerized tasks there is some
  model that a novice will use in his or her first attempts. We need to
  understand when it is appropriate to appeal to this model, and, when
  necessary, how to move a novice to some more appropriate model. (Bonar
  \& Soloway, 1983, p. 13)
\end{quote}

We assume Bonar and Soloway structured the final line of that quote deliberately. If
so, their phrasing has three consequences:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Appealing to novice's existing models gets precedence. That is,
  understanding how to leverage novices' existing knowledge comes first
  in research.
\item
  Changing the models novices have comes next, and explicitly ``when necessary.''
\item
  They speak of ``how to move a novice to some more appropriate model,''
  which does not necessarily entail rejecting a student's existing model, treating it as a misconception to be corrected, or otherwise ignoring what productive elements are present in a given novice model.
\end{enumerate}

We believe that taken together, these points convey a sense of how Bonar and Soloway \cite{bonar_uncovering_1983}
viewed learning and instruction in computing. Instruction explicitly
includes appeals to prior models and knowledge students might already
have. Learning, meanwhile, involves the movement \emph{when necessary}
to more appropriate models of computation. As we explain in the next
section, such a view of understanding and refining student ideas---in contrast to diagnosing the deficiencies in and replacement of student ideas---exactly aligns with a particular branch of
constructivism, where cognition is viewed as the complex activation of
manifold resources for thinking and knowing.

\subsection{Examples motivate the need for contextual-sensitivity in modeling programming cognition}\label{examples-motivate-the-need-for-contextual-sensitivity-in-modeling-programming-cognition}

Let's begin with two motivating examples. Our aim with these examples is
to show how a practicing programmer might employ specific, distinct
conceptual models to reason locally about a piece of code.

\subsubsection{Example 1: Thinking With Kinematics Can Transform a Debugging Problem}

First,
consider variants of the PASCAL statements from Bonar and Soloway
(1983), where an assignment statement worked to increment a value and
store the result back to that value. Below are JavaScript statements that, as programmers, we have actually written in code as part of our careers. Each statement
adheres to the structural similarity in Bonar and Soloway's PASCAL example \cite{bonar_uncovering_1983} discussed earlier. But, the comment above each statement reflects the \emph{functional understandings} \cite{disessa_models_1986} we made use of to write, interpret, and debug the code we were working on.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\CommentTok{// Increment a counter}
\NormalTok{x }\OperatorTok{=} \NormalTok{x }\OperatorTok{+} \DecValTok{1}

\CommentTok{// Advance a simulation forward}
\NormalTok{t }\OperatorTok{=} \NormalTok{t }\OperatorTok{+} \NormalTok{dt}

\CommentTok{// Move an object under uniform velocity}
\NormalTok{x_position }\OperatorTok{=} \NormalTok{x_position }\OperatorTok{+} \NormalTok{displacement}

\CommentTok{// Accelerate an object along the x-dimension}
\NormalTok{x_position }\OperatorTok{=} \NormalTok{x_position }\OperatorTok{+} \AttributeTok{displacement}\NormalTok{(t)}

\CommentTok{// Jitter a plot point using a stochastic function}
\NormalTok{y_position }\OperatorTok{=} \NormalTok{y_position }\OperatorTok{+} \AttributeTok{random_noise}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

We stress the comments reflect \emph{how one might think about}
each programming statement. By no means are we making normative
claims about how one \emph{ought} to think about it, or whether the
statement actually does what its variable names might suggest it does. Rather,
``How we might think about it'' reflects the kind of local meaning or
interpretation we might attach to such a statement when we work with it,
given our understanding of its role and context.

Consider specifically what would happen if we found ourselves needing to debug lines 2 and 11. Line 2 could very well be
an incrementer in some kind of iterative code. If we had to debug loop code
that employs line 2, what we might do is try inserting
intermediate print statements to see the value of x. We might also call on our knowledge that it's being incremented by 1 to check whether the difference between any two successive printouts is 1; if it isn't, we immediately know something's wrong. But to diagnose a potential problem in line 11, we might take an altogether different strategy.


In line
11's case, it could very well be that line 11's function is animating
images on a screen. Suppose that's the case. If there's a problem with that code, one of the
easiest ways we might notice is that the \emph{acceleration} seems off in the
animation. Consequently, in debugging we might call upon knowledge we have
from kinematics to conceptually model what our code is doing. We might try inserting code that draws a dot at the
animated object's on-screen position with each iteration, leaving a trail of dots we can
visually inspect. We could then look at the path of the object's
trajectory and the spacing patterns between successive dots as a
first-pass test of whether the code achieves the motion we want. (If, for example, our code is supposed to achieve a cubic easing animation, but the dots in the trail are all evenly spaced, basic kinematics tells us our object isn't accelerating at all. And, if there's no acceleration, we can pursue a strong hunch that the \texttt{displacement(t)}) function is returning the same constant value with each iternation.

To be clear, it's not just that graphics might improve our efficiency in
debugging a statement like line 11. Rather, applying an interpretive frame that
treats an assignment statement as a kinematic position update lets us
\emph{use conceptual knowledge from physics} to diagnose and fix
problems in code. For a comparative perspective, consider Hutchins's argument that for aircraft pilots, ringing an aircraft speedometer with physical markers transforms the cognition involved in landing a plane:

\begin{quote}
  Without a speed bug, on final approach the PF [Pilot Flying] must remember the approach speed, read the airspeed indicator scale to find the remembered value of the approach speed on the airspeed indicator scale, and compare the position of the ASI [Airspeed Indicator] needle on the scale with the position of the approach speed on the scale. With the salmon bug set, the pilot no longer needs to read the airspeed indicator scale. He or she simply looks to see whether or not the indicator needle is lined up with the salmon bug. Thus, a memory and scale reading task is transformed into a judgment of spatial adjacency. \cite{hutchins_how_1995}
\end{quote}

Our physics debugging example and Hutchins's speed bug example \cite{hutchins_how_1995} share two core traits:

\begin{enumerate}
  \tightlist
  \item Cognition gets \emph{distributed} \cite{hutchins_distributed_2000,hutchins_cognition_1995} across time and space.
  \item That distribution doesn't simply enhance, but rather \emph{transforms} the nature of the activity, allowing cognitive agents to bring to bear resources that the prior or original context didn't afford.
\end{enumerate}

In Hutchins's \cite{hutchins_how_1995} example, pilots distribute cognition across time (1) by making approach speed calculations mid-flight, well before they're needed. Pilots then distribute those calculations across space (2) by ringing the speedometer with bugs to represent distinct speeds. And, it is this act of distribution that lets pilots use spatial-adjacency perception (visually making sure the needle is on the bugs) during approach instead of having to calculate, compute, and compare speed numbers during approach.

In our kinematics debugging example, cognition gets distributed across time and space (1) by creating a visual trace of the animated object's position (a persistent trail of dots). And, it is this act of dot-tracing that lets a programmer invokve spatial-adjacency perception and conceptual kinematics knowledge (how positions uniformly sampled in time can reflect constant velocity vs. acceleration) that wouldn't seem applicable if the reassignment statement were stripped of its context.

the cognitive act of debugging in this instance.    There,  For comparison, consider

 If we view the assignment statement as proposing
something about the motion of an object---as, for example, when sense-making in science and engineering students can view equations as ``saying something'' about how a system behaves[blinded]---a
field of knowledge and concomitant techniques from physics become
available to me to think with. But, if we focus only on the
semantic-level equivalence of statements 1 through 5, there would be no
obvious reason for me to access what we know about physics in order to
reason about the code.

\subsubsection{Example 2: The Plus Sign Means Lots of Things}

Our second example concerns statements that use the same symbol template for fundamentally different kinds of computation. In our JavaScript example statements, all code came from the same language. But, another phenomenon comes
into play \emph{across} different languages when they use the same symbology (written patterns) to stand for
conceptually different operations. The statements below are examples of what look
like semantically-equivalent operations, but in fact are not.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// C - Increments the value of i by 1}
\NormalTok{i = i + }\DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// JavaScript - Appends "ly" to word.toString()}
\NormalTok{word }\OperatorTok{=} \NormalTok{word }\OperatorTok{+} \StringTok{"ly"}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# R/ggplot2 - Composes a layer of points onto a plot}
\NormalTok{p =}\StringTok{ }\NormalTok{p +}\StringTok{ }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}


The catch here is that the plus operator takes on different roles in
different languages because of how those languages define its use.
Statement 1 increments a number in C; Statement 2 appends the letters
``ly'' to a string; Statement 3 composes a layer of points onto a statistical
graphics plot. These different kinds of operations become even more
apparent and consequential when, for example, such statements are
repeated in the same language within the same file, as we'll see in Example 3.

\subsubsection{Example 3: The Same Symbol Template \emph{Within} The Same Language Can Still Mean Different Things}

In the R/ggplot2 code below, the author uses multiple
reassignment statements to compose a statistical graphics plot.

\begin{Shaded}
\begin{Highlighting}[numbers=left,,]
\NormalTok{p =}\StringTok{ }\KeywordTok{InitializeGgplot_1w}\NormalTok{()}
\NormalTok{p =}\StringTok{ }\NormalTok{p +}\StringTok{ }\KeywordTok{GrandMeanLine}\NormalTok{(owp)}
\NormalTok{p =}\StringTok{ }\NormalTok{p +}\StringTok{ }\KeywordTok{GrandMeanPoint}\NormalTok{(owp)}
\NormalTok{p =}\StringTok{ }\NormalTok{p +}\StringTok{ }\KeywordTok{ScaleX_1w}\NormalTok{(owp)}
\NormalTok{p =}\StringTok{ }\NormalTok{p +}\StringTok{ }\KeywordTok{ScaleY_1w}\NormalTok{(owp)}
\end{Highlighting}
\end{Shaded}

Despite the syntactic similarity, The
layered creation of a plot invites a very different kind of conceptual
interpretation than, say, repeatedly accumulating numbers into a running
sum. One obvious reason for thinking about this code with a different
interpretive frame than incrementation is that numeric addition is commutative; composing a
plot is not necessarily commutative. So, despite the syntactic similarity, statements that
compose a plot using reassignment (as above) do not obey the same
rules as reassignments for a running total. But, it turns out the statements above don't obey the same rules of string concatenation either. Within this code
block, statements that look alike perform operations of a different
nature. While some expressions (lines 2 and 3) compose
visual layers onto a plot, others (lines 4 and 5) modify features of the plot, like the x and y scales.

Given these motivating examples, it seems sensible to think there's
utility in a programmer having different conceptual metaphors available
to think about and work with code.

We believe that working from conceptual metaphors---in our example, attacking a debugging problem by exploiting animation and drawing from physics knowledge---achieves the same kind of transformation Hutchins describes.

Example
2 shows that across languages, programmers might have to deploy
different conceptual metaphors to reason about statements in a
locally-consistent way. Knowing that plots in ggplot2 can be composed
layer-by-layer with reassignment is crucial if you're trying to write or
understand code that creates statistical graphics. But, we would argue
that thinking about $\Box = \Box + \Box$ as ``compose new layer onto plot'' can and
does appeal to different kinds of knowledge when compared to thinking
about $\Box = \Box + \Box$ as ``include this addend in the sum,'' which itself can
and does appeal to different kinds of concepts when compared to thinking
about $\Box = \Box + \Box$ as ``increment the counter.''

Stepping back, we can build the following argument

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Programming can be helped by applying conceptual models to code,
  particularly when relevant domain-knowledge structures can
  advantageously transform a problem (example 1)
\item
  But, conceptual models don't work all the time for all statements.
  Because languages are designed differently, the same syntax can
  actually correspond to very different operations in code (example 2).
  And, that's true both within and across languages (example 3).
\item
  Consequently, it makes less sense to treat conceptual models as right
  or wrong, and more sense to treat them as differentially advantageous
  for thinking about what a piece of code does. (Thinking a ``+''
  implies numerical addition isn't \emph{globally wrong} in JavaScript,
  but it won't explain why 1 + ``1'' yields ``11'' as a result.)
\item
  It seems plausible that successful programmers, when reasoning about
  or writing code, are able to dynamically access or deploy conceptual
  models that are advantageous given the context (language, syntax,
  surrounding code). Certainly prior research demonstrates novices and experts both have resources for creating, evaluating, and adapting their own conceptual metaphors to suit the context of the problem \cite{hammer_static_2011,izsak_we_2003,izsak_students_2004}
\item
  To model how programmers think with conceptual models, a suitable
  framework should be able to account for the dynamic, context-sensitive
  deployment of conceptual knowledge.
\item
  To model how programmers develop expertise, a suitable framework
  should be able to describe higher-order phenomena. Such phenomena
  include explaining how programmers come to have conceptual models or
  generate new ones, why they decide to deploy them, and how programmers
  consider which conceptual model (i.e., which way to think about code)
  is appropriate.
\end{enumerate}

Taken together, these assertions propose criteria for how we might
strive to model cognition in programming. Our modeling frameworks should
be context-dependent, dynamic, and capable of explaining where
conceptual models come from. They should also be able to account for
phenomena that are not themselves conceptual, including what directs the
use of certain kinds of conceptual knowledge. In the learning sciences,
such models already exist and have proven useful and productive for
thinking about thinking.

\subsection{Manifold models of cognition can explain context-dependence
and the growth of
expertise}\label{manifold-models-of-cognition-explain-context-dependence-and-the-growth-of-expertise}

In 1993, a pair of articles in the learning sciences staked a strong
claim for viewing knowledge as a network of pieces, isolated enough to
be locally triggered but trainable enough to fire in larger concerted
patterns \cite{disessa_epistemology_1993,smith_misconceptions_1993}. Informed
in part by agent-based accounts of cognition \cite{minsky_society_1986} and complex
systems models \cite{disessa_why_2002}, the central tenets of an ``in-pieces''
approach hold that knowledge is emergent from interacting primitives,
rather than unitary and monolithic. An example from Smith, diSessa, and
Roschelle helps illustrate the point.

The authors show that we might think of a rubber band as a different
conceptual entity depending on context. In several different
situations---wrapped around a newspaper, suspending a bob weight, pulled taut as a string, spun
to store energy in a toy plane propeller---we intuitively think about
the rubber band's physical behavior differently: one as a negligible
part of the newspaper's point mass, two different kinds of harmonic pendulums, and finally a torsional spring. Those
differences in intuitive thinking reflect the contextual dependency of
what we know about the physical world:

\begin{quote}
  In each of the rubberband examples, various pieces of intuitive physical
  knowledge describe the mechanism at work: the rubber band binds the
  newspaper, grips the jar lid, and acts a source of springiness for the
  bobbing object. Although a mapping cannot be made from the rubberband to
  scientific entities, it is quite easy to map these qualitatively
  distinct physical processes to scientific entities and laws. For
  example, instances of binding almost always map to a practically rigid
  body. Likewise, gripping maps to friction forces, and springiness maps
  to Hooke's law. This suggests that applicability can depend directly on
  our intuitive knowledge---knowledge that exists prior to any formal
  scientific training \cite{smith_misconceptions_1993}.
\end{quote}

The in-pieces approach to modeling cognition has been used, among other
things, to explain how experts reason about fractions and decimals \cite{smith_misconceptions_1993}, how students reason about forces in physics \cite{disessa_what_1998,disessa_epistemology_1993,hammer_misconceptions_1996,sherin_how_2001},
how students construct and evaluate algebraic representations of
physical situations \cite{izsak_we_2003,izsak_students_2004}, and how knowledge transfers across
contexts \cite{hammer_resources_2005,wagner_transfer_2006}. Because its starting
assumption is that knowledge is fragmented, knowledge-in-pieces can
account for wide variations of how people---particularly novices---use
knowledge on a moment-to-moment basis. In other words, because it
assumes knowledge is local, it can still explain the kinds of
globally-inconsistent ways people might reason about physical situations
\cite{disessa_epistemology_1993}. As a framework, an in-pieces approach ultimately argues
that models of concept replacement and good/bad criteria for knowledge
should be supplanted by a learning model of alignment/refinement of
prior knowledge and the consideration of knowledge as
productive/unproductive.

Hammer and colleagues have worked to extend the in-pieces approach to
explain how students' epistemological activity---how they orient toward
knowledge and knowing in a context \cite{hammer_resources_2005,hammer_form_2002,elby_substance_2001}. Specifically, those authors use two core theoretical
constructs to explain students' stances toward knowledge and knowing:

\begin{itemize}
\item
  \emph{Epistemological Resources} \cite{hammer_resources_2005} are the epistemological equivalent of
  diSessa's phenomenological primitives (p-prims) \cite{disessa_epistemology_1993}. Resources, the
  authors propose, are the atomic units involved in how people cognize
  about the source of knowledge, the nature of knowledge, and
  epistemological activities \cite{hammer_tapping_2003,louca_epistemological_2004}.
\item
  \emph{Epistemological Frames} are the emergent result of subsets of
  resources acting in concert. Drawing from both Goffman's
  sociological notion of frame as structures of expectations \cite{goffman_frame_1974} and
  subsequent work on framing in discourse \cite{tannen_framing_1993},
  epistemological frames are a participant's local answer to the
  question ``what is it {[}specifically, what knowledge activity{]}
  that's going on here'' \cite{goffman_frame_1974}.
\end{itemize}

Resources and frames can interact in activity settings to produce
larger-scale patterns called ``epistemological coherences'' \cite{rosenberg_multiple_2006} where evidence from data suggests that a
network of discrete cognitive units can nonetheless give rise to stable
cognition.

An example helps ground this in-pieces approach to epistemology. Russ, Coffey, Hammer, and Hutchison, describe the
situation where an elementary student reasons about why an empty juice
box collapses when you suck on the straw \cite{russ_making_2008}. One student gives what the
authors deem to be an excellent mechanistic account of why the juice box
collapses:

\begin{quote}
  In explaining the phenomenon, Erin focuses on the role played by the air located inside the juice box. She describes the air inside as actively pushing out on all sides of the box holding them out and flat. When that air is removed from the box (by sucking it out through the straw), there is no longer anything pushing from the inside to hold the box out, so the sides cave in. We call this description of the phenomenon the “inside-pusher” model because of its focus on what happens inside the box. \cite{russ_making_2008}
\end{quote}

But, as the teacher seems to steer the discussion toward canonically correct
vocabulary---in this case, ``pressure''---and Erin clearly pulls back
from her mechanistic reasoning, seems much more diffident, and claims
that pressure is hard to explain. That example highlights the disconnect
between doing science as knowing vocabulary and doing science as
reasoning mechanistically. Moreover, it strikingly highlights that a
student who by all accounts produced an excellent explanation of how
pressure works was left nonetheless with the impression that pressure
was hard to explain. In other words, in that moment what counted as knowing was using the word pressure. Erin's mechanistic explanation---beautiful and complex as it was---didn't use that magic word, and in a possible effort to push the class toward canonical behavior, the teacher shut down Erin's reasoning.

\subsection{Acknowledgments}\label{acknowledgments}

Blinded for review.

\clearpage

\bibliographystyle{acm}
\bibliography{bibliography}
